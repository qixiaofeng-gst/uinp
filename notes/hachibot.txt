哈崎机器人：
http://www.hachibot.vip

调研项目：
https://github.com/leggedrobotics/raisimGym - working on it
https://github.com/leggedrobotics/towr
https://github.com/mit-biomimetics/Cheetah-Software - target hardware relevant
\\wsl$\Ubuntu-18.04\home\qixiaofeng\git-repos

In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers.

数值的研究方式是什么？
- 是不是存在一个实践检验过的模型，能指导数值的调整？
- 还是目前都是使用试验、记录、再试验的方式收集经验数据？

Useful information:
1. pybind11 is the bridge between c++ and python
2. check Qt installation: qtdiag
3. URDF: Unified Robot Description Format; SDF: Simulation Description Format; MJCF: Multi-Joint dynamics with Contact Format
4. Eigen: C++ template library for matrix/verctor/numerical solver, pure header files without binary library
5. Executables for Qt might start correctly with -qt=qt5 as argument

这两天对需求和代码粗浅的理解之后，大概弄了个分层设计（没什么高深的，分个层方便描述、理解和沟通，预期每一层都至少是一个独立工程）：
1. 描述格式适配（输入层）
   - 输入：URDF，SDF，MJCF 等格式
   - 输出：单一格式的机器人描述，比如 URDF，或者我们自定
   - 对不同目标（模拟器或机器人）可能要进行数值调整，因此输出可能针对不同目标生成独立的版本
   - 可能是个工具集合，针对不同格式和目标有不同工具
2. 机器人控制模型训练（训练层，核心工程）
   - 输入：机器人描述，环境描述，训练过的控制模型
   - 输出：训练过的控制模型
   - 预期是 C++ 和 Python 混合的工程
   - 与输入层类似，可能针对不同目标需要不同的训练环境
   - 本层的输入输出在概念上是有不同目标之分的，但是代码逻辑上是不用区分不同目标的
   - 本层的输入输出的内容格式和训练逻辑是稳定的、一致的
   - 模型的训练预期是要依赖某种模拟器的，最好能选一个开源的模拟器
3. 机器人控制模型导出（转译/输出层）
   - 输入：训练过的控制模型
   - 输出：用于控制机器人或模拟器的可执行程序
   - 主要需要将训练过的控制模型针对不同目标进行处理
   - 可能是个工具集合，针对不同目标有不同工具

目标：
1. raisimLib 捋清楚：先读一读 manual。
2. 把 raisimGym 的流程捋清楚：训练是依据的什么？训练结果是怎么运行出来的？
3. 找到抽取相对独立的训练算法的方式。
4. 设计出能部署至不同对象（模拟器，真机）的部署系统。

杨淼提供的目标：
1. raisimGym(rsg) 依赖的是 raisimLib 的仿真环境，我们需要提供对其他仿真环境的支持，比如 mit、ROS 等
2. rsg 和 ppo 耦合在一起了，需要解耦以便重用
3. 需要灵活便捷的部署方式
4. 通过抽象和新增工具的形式来提供对开发和尝试不同 reward 的支持

cached commands for ROS in WSL:
export LOCAL_BUILD=~/git-repos/raisim-workspace/raisim-build/
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$LOCAL_BUILD/lib
mv /mnt/c/Users/qixia/Downloads/*.whl ./ && mv /mnt/c/Users/qixia/Downloads/*.tar.gz ./
------- install tensorflow-gpu:
pip3 install setuptools-46.0.0-py3-none-any.whl six-1.14.0-py2.py3-none-any.whl numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl Markdown-3.2.1-py2.py3-none-any.whl protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl grpcio-1.27.2-cp36-cp36m-manylinux1_x86_64.whl tensorboard-1.14.0-py3-none-any.whl h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl
------- install scipy:
pip3 install numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl
------- install pandas:
pip3 install pytz-2019.3-py2.py3-none-any.whl numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl six-1.14.0-py2.py3-none-any.whl
------- install opencv-python:
pip3 install opencv_python-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl
------- install matlablib:
pip3 install matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl setuptools-46.0.0-py3-none-any.whl six-1.14.0-py2.py3-none-any.whl
------- install pylet:
pip3 install pyglet-1.5.0-py2.py3-none-any.whl future-0.18.2.tar.gz
------- install atari-py:
pip3 install atari_py-0.2.6-cp36-cp36m-manylinux1_x86_64.whl numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl six-1.14.0-py2.py3-none-any.whl
------- setup raisimGym demo:
python3 setup.py install --CMAKE_PREFIX_PATH $LOCAL_BUILD --env anymal

强化学习（Reinforcement Learning, RL），又称再励学习、评价学习或增强学习，是机器学习的范式和方法论之一。
强化学习是智能体（Agent）以“试错”的方式进行学习，通过与环境进行交互获得的奖赏指导行为，目标是使智能体获得最大的奖赏。
强化学习不同于连接主义学习中的监督学习，主要表现在强化信号上，强化学习中由环境提供的强化信号是对产生动作的好坏作一种评价(通常为标量信号)，而不是告诉强化学习系统(RLS)如何去产生正确的动作。
由于外部环境提供的信息很少，RLS必须靠自身的经历进行学习。通过这种方式，RLS在行动-评价的环境中获得知识，改进行动方案以适应环境。

深度学习(DL, Deep Learning)是机器学习(ML, Machine Learning)领域中一个新的研究方向。
它被引入机器学习使其更接近于最初的目标——人工智能(AI, Artificial Intelligence)。
深度学习是学习样本数据的内在规律和表示层次，这些学习过程中获得的信息对诸如文字，图像和声音等数据的解释有很大的帮助。
它的最终目标是让机器能够像人一样具有分析学习能力，能够识别文字、图像和声音等数据。 深度学习是一个复杂的机器学习算法，在语音和图像识别方面取得的效果，远远超过先前相关技术。
深度学习在搜索技术，数据挖掘，机器学习，机器翻译，自然语言处理，多媒体学习，语音，推荐和个性化技术，以及其他相关领域都取得了很多成果。
深度学习使机器模仿视听和思考等人类的活动，解决了很多复杂的模式识别难题，使得人工智能相关技术取得了很大进步。
深度学习是一类模式分析方法的统称，就具体研究内容而言，主要涉及三类方法：
(1)基于卷积运算的神经网络系统，即卷积神经网络(CNN)。
(2)基于多层神经元的自编码神经网络，包括自编码( Auto encoder)以及近年来受到广泛关注的稀疏编码两类( Sparse Coding)。
(3)以多层自编码神经网络的方式进行预训练，进而结合鉴别信息进一步优化神经网络权值的深度置信网络(DBN)。
通过多层处理，逐渐将初始的“低层”特征表示转化为“高层”特征表示后，用“简单模型”即可完成复杂的分类等学习任务。
由此可将深度学习理解为进行“特征学习”（feature learning）或“表示学习”（representation learning）。
以往在机器学习用于现实任务时，描述样本的特征通常需由人类专家来设计，这成为“特征工程”（feature engineering）。
众所周知，特征的好坏对泛化性能有至关重要的影响，人类专家设计出好特征也并非易事。
特征学习（表征学习）则通过机器学习技术自身来产生好特征，这使机器学习向“全自动数据分析”又前进了一步。
近年来，研究人员也逐渐将这几类方法结合起来，如对原本是以有监督学习为基础的卷积神经网络结合自编码神经网络进行无监督的预训练，进而利用鉴别信息微调网络参数形成的卷积深度置信网络。
与传统的学习方法相比，深度学习方法预设了更多的模型参数，因此模型训练难度更大，根据统计学习的一般规律知道，模型参数越多，需要参与训练的数据量也越大。
20世纪八九十年代由于计算机计算能力有限和相关技术的限制，可用于分析的数据量太小，深度学习在模式分析中并没有表现出优异的识别性能。自从2006年， Hinton等提出快速计算受限玻耳兹曼机(RBM)网络权值及偏差的CD-K算法以后，RBM就成了增加神经网络深度的有力工具，导致后面使用广泛的DBN(由 Hinton等开发并已被微软等公司用于语音识别中)等深度网络的出现。与此同时，稀疏编码等由于能自动从数据中提取特征也被应用于深度学习中。基于局部数据区域的卷积神经网络方法今年来也被大量研究。

机器学习的分类
——————————————
几十年来，研究发表的机器学习的方法种类很多，根据强调侧面的不同可以有多种分类方法。
基于学习策略的分类
(1) 模拟人脑的机器学习
符号学习：模拟人脑的宏现心理级学习过程，以认知心理学原理为基础，以符号数据为输入，以符号运算为方法，用推理过程在图或状态空间中搜索，学习的目标为概念或规则等。符号学习的典型方法有记忆学习、示例学习、演绎学习.类比学习、解释学习等。
神经网络学习(或连接学习)：模拟人脑的微观生理级学习过程，以脑和神经科学原理为基础，以人工神经网络为函数结构模型，以数值数据为输人，以数值运算为方法，用迭代过程在系数向量空间中搜索，学习的目标为函数。典型的连接学习有权值修正学习、拓扑结构学习。
(2) 直接采用数学方法的机器学习
主要有统计机器学习。 [2] 
统计机器学习是基于对数据的初步认识以及学习目的的分析，选择合适的数学模型，拟定超参数，并输入样本数据，依据一定的策略，运用合适的学习算法对模型进行训练，最后运用训练好的模型对数据进行分析预测。
统计机器学习三个要素：
模型(model)：模型在未进行训练前，其可能的参数是多个甚至无穷的，故可能的模型也是多个甚至无穷的，这些模型构成的集合就是假设空间。
策略(strategy)：即从假设空间中挑选出参数最优的模型的准则。模型的分类或预测结果与实际情况的误差(损失函数)越小，模型就越好。那么策略就是误差最小。
算法(algorithm)：即从假设空间中挑选模型的方法(等同于求解最佳的模型参数)。机器学习的参数求解通常都会转化为最优化问题，故学习算法通常是最优化算法，例如最速梯度下降法、牛顿法以及拟牛顿法等。
基于学习方法的分类
(1) 归纳学习
符号归纳学习：典型的符号归纳学习有示例学习、决策树学习。
函数归纳学习(发现学习)：典型的函数归纳学习有神经网络学习、示例学习、发现学习、统计学习。
(2) 演绎学习
(3) 类比学习：典型的类比学习有案例(范例)学习。
(4) 分析学习：典型的分析学习有解释学习、宏操作学习。 [2] 
基于学习方式的分类
(1) 监督学习(有导师学习)：输入数据中有导师信号，以概率函数、代数函数或人工神经网络为基函数模型，采用迭代计算方法，学习结果为函数。 [2] 
(2) 无监督学习(无导师学习)：输入数据中无导师信号，采用聚类方法，学习结果为类别。典型的无导师学习有发现学习、聚类、竞争学习等。 [2] 
(3) 强化学习(增强学习)：以环境反惯(奖/惩信号)作为输人，以统计和动态规划技术为指导的一种学习方法。 [2] 
基于数据形式的分类
(1) 结构化学习：以结构化数据为输人，以数值计算或符号推演为方法。典型的结构化学习有神经网络学习、统计学习、决策树学习、规则学习。 [2] 
(2) 非结构化学习：以非结构化数据为输人，典型的非结构化学习有类比学习案例学习、解释学习、文本挖掘、图像挖掘、Web挖掘等。 [2] 
基于学习目标的分类
(1) 概念学习：学习的目标和结果为概念，或者说是为了获得概念的学习。典型的概念学习主要有示例学习。
(2) 规则学习：学习的目标和结果为规则，或者为了获得规则的学习。典型规则学习主要有决策树学习。
(3) 函数学习：学习的目标和结果为函数，或者说是为了获得函数的学习。典型函数学习主要有神经网络学习。 [2] 
(4) 类别学习：学习的目标和结果为对象类，或者说是为了获得类别的学习。典型类别学习主要有聚类分析。
(5) 贝叶斯网络学习：学习的目标和结果是贝叶斯网络，或者说是为了获得贝叶斯网络的一种学习。其又可分为结构学习和多数学习。 [2] 
常见算法
——————————————
决策树算法
决策树及其变种是一类将输入空间分成不同的区域，每个区域有独立参数的算法。决策树算法充分利用了树形模型，根节点到一个叶子节点是一条分类的路径规则，每个叶子节点象征一个判断类别。先将样本分成不同的子集，再进行分割递推，直至每个子集得到同类型的样本，从根节点开始测试，到子树再到叶子节点，即可得出预测类别。此方法的特点是结构简单、处理数据效率较高。 [4] 
朴素贝叶斯算法
朴素贝叶斯算法是一种分类算法。它不是单一算法，而是一系列算法，它们都有一个共同的原则，即被分类的每个特征都与任何其他特征的值无关。朴素贝叶斯分类器认为这些“特征”中的每一个都独立地贡献概率，而不管特征之间的任何相关性。然而，特征并不总是独立的，这通常被视为朴素贝叶斯算法的缺点。简而言之，朴素贝叶斯算法允许我们使用概率给出一组特征来预测一个类。与其他常见的分类方法相比，朴素贝叶斯算法需要的训练很少。在进行预测之前必须完成的唯一工作是找到特征的个体概率分布的参数，这通常可以快速且确定地完成。这意味着即使对于高维数据点或大量数据点，朴素贝叶斯分类器也可以表现良好。 [4] 
支持向量机算法
基本思想可概括如下：首先，要利用一种变换将空间高维化，当然这种变换是非线性的，然后，在新的复杂空间取最优线性分类表面[8]。由此种方式获得的分类函数在形式上类似于神经网络算法。支持向量机是统计学习领域中一个代表性算法，但它与传统方式的思维方法很不同，输入空间、提高维度从而将问题简短化，使问题归结为线性可分的经典解问题。支持向量机应用于垃圾邮件识别，人脸识别等多种分类问题。 [4] 
随机森林算法
控制数据树生成的方式有多种，根据前人的经验，大多数时候更倾向选择分裂属性和剪枝，但这并不能解决所有问题，偶尔会遇到噪声或分裂属性过多的问题。基于这种情况，总结每次的结果可以得到袋外数据的估计误差，将它和测试样本的估计误差相结合可以评估组合树学习器的拟合及预测精度。此方法的优点有很多，可以产生高精度的分类器，并能够处理大量的变数，也可以平衡分类资料集之间的误差。 [4] 
人工神经网络算法
人工神经网络与神经元组成的异常复杂的网络此大体相似，是个体单元互相连接而成，每个单元有数值量的输入和输出，形式可以为实数或线性组合函数。它先要以一种学习准则去学习，然后才能进行工作。当网络判断错误时，通过学习使其减少犯同样错误的可能性。此方法有很强的泛化能力和非线性映射能力，可以对信息量少的系统进行模型处理。从功能模拟角度看具有并行性，且传递信息速度极快。 [4] 
Boosting与Bagging算法
Boosting是种通用的增强基础算法性能的回归分析算法。不需构造一个高精度的回归分析，只需一个粗糙的基础算法即可，再反复调整基础算法就可以得到较好的组合回归模型。它可以将弱学习算法提高为强学习算法，可以应用到其它基础回归算法，如线性回归、神经网络等，来提高精度。Bagging和前一种算法大体相似但又略有差别，主要想法是给出已知的弱学习算法和训练集，它需要经过多轮的计算，才可以得到预测函数列，最后采用投票方式对示例进行判别。 [4] 
关联规则算法
关联规则是用规则去描述两个变量或多个变量之间的关系，是客观反映数据本身性质的方法。它是机器学习的一大类任务，可分为两个阶段，先从资料集中找到高频项目组，再去研究它们的关联规则。其得到的分析结果即是对变量间规律的总结。 [4] 
EM（期望最大化）算法
在进行机器学习的过程中需要用到极大似然估计等参数估计方法，在有潜在变量的情况下，通常选择EM算法，不是直接对函数对象进行极大估计，而是添加一些数据进行简化计算，再进行极大化模拟。它是对本身受限制或比较难直接处理的数据的极大似然估计算法。 [4] 
深度学习
深度学习(DL, Deep Learning)是机器学习(ML, Machine Learning)领域中一个新的研究方向，它被引入机器学习使其更接近于最初的目标——人工智能(AI, Artificial Intelligence)。
深度学习是学习样本数据的内在规律和表示层次，这些学习过程中获得的信息对诸如文字，图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力，能够识别文字、图像和声音等数据。 深度学习是一个复杂的机器学习算法，在语音和图像识别方面取得的效果，远远超过先前相关技术。
深度学习在搜索技术、数据挖掘、机器学习、机器翻译、自然语言处理、多媒体学习、语音、推荐和个性化技术，以及其他相关领域都取得了很多成果。深度学习使机器模仿视听和思考等人类的活动，解决了很多复杂的模式识别难题，使得人工智能相关技术取得了很大进步。